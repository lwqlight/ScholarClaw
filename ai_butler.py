import os
import requests
from zhipuai import ZhipuAI
import schedule
import time
from datetime import datetime
from dotenv import load_dotenv

# ================= 1. ç¯å¢ƒåˆå§‹åŒ– =================
# åŠ è½½ .env æ–‡ä»¶ä¸­çš„å˜é‡
load_dotenv()

ZHIPU_API_KEY = os.getenv("ZHIPU_API_KEY")
FEISHU_WEBHOOK_URL = os.getenv("FEISHU_WEBHOOK_URL")

# å®‰å…¨æ ¡éªŒï¼šå¦‚æœæ²¡æœ‰è¯»åˆ°å¯†é’¥ï¼Œç›´æ¥æŠ¥é”™åœæ­¢ï¼Œé˜²æ­¢çè·‘
if not ZHIPU_API_KEY or not FEISHU_WEBHOOK_URL:
    print("âŒ è‡´å‘½é”™è¯¯ï¼šæœªæ£€æµ‹åˆ° API Key æˆ– Webhook é“¾æ¥ï¼è¯·æ£€æŸ¥ .env æ–‡ä»¶ã€‚")
    exit(1)

# ================= 2. ä¸“å±é…ç½®åŒº =================
TARGET_KEYWORDS = [
    "VLA", "End-to-End", "Embodied", "Humanoid", "Manipulation", 
    "Sim-to-Real", "Reinforcement Learning", "Dexterous", "Diffusion"
]
TARGET_VENUES = "CoRL,ICRA,IROS,RSS,Science Robotics,IEEE Transactions on Robotics"

client = ZhipuAI(api_key=ZHIPU_API_KEY)

# ================= 3. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° =================
def fetch_top_tier_papers():
    print(f"\n[{datetime.now().strftime('%H:%M:%S')}] é›·è¾¾å‡çº§ï¼æ­£åœ¨æ‰«æå…¨çƒæœºå™¨äººé¡¶ä¼š/é¡¶åˆŠ...")
    unique_papers = {} 
    current_year = datetime.now().year
    year_range = f"{current_year-1}-{current_year}" 

    for keyword in TARGET_KEYWORDS:
        print(f"  -> æ­£åœ¨æ£€ç´¢å…³é”®è¯: {keyword} ...")
        url = "https://api.semanticscholar.org/graph/v1/paper/search"
        params = {
            "query": keyword,
            "venue": TARGET_VENUES,
            "year": year_range,
            "fields": "title,abstract,url,venue,year",
            "limit": 3 
        }
        
        try:
            response = requests.get(url, params=params, timeout=10)
            if response.status_code == 200:
                data = response.json()
                if 'data' in data:
                    for paper in data['data']:
                        if not paper.get('abstract'): 
                            continue
                        title = paper.get('title')
                        if title not in unique_papers:
                            venue_name = paper.get('venue', 'é¡¶çº§ä¼šè®®')
                            year = paper.get('year', current_year)
                            unique_papers[title] = {
                                "title": f"[{venue_name} {year}] {title}", 
                                "link": paper.get('url', 'https://www.semanticscholar.org/'),
                                "summary": paper.get('abstract')
                            }
            time.sleep(1) 
        except Exception as e:
            print(f"æ£€ç´¢ {keyword} æ—¶ç½‘ç»œå¼€å°å·®äº†: {e}")
            
    return list(unique_papers.values())[:3] 

def ai_summarize(paper):
    print(f"æ­£åœ¨è¯·æ™ºè°±AIç²¾è¯»é¡¶ä¼šæ–‡ç« : {paper['title'][:30]}...")
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªé¡¶çº§çš„å…·èº«æ™ºèƒ½ä¸æœºå™¨äººå­¦æœ¯åŠ©ç†ã€‚è¯·é˜…è¯»ä»¥ä¸‹è¿™ç¯‡æœ€æ–°å‘è¡¨åœ¨é¡¶çº§ä¼šè®®/æœŸåˆŠä¸Šçš„è®ºæ–‡æ‘˜è¦ï¼Œç”¨ä¸­æ–‡ä¸ºæˆ‘æ€»ç»“ã€‚
    è¦æ±‚ï¼š
    1. ç”¨ä¸€å¥å¤§ç™½è¯æ¦‚æ‹¬å®ƒè§£å†³äº†ä»€ä¹ˆè¡Œä¸šç—›ç‚¹ã€‚
    2. åˆ—å‡º2-3ä¸ªæ ¸å¿ƒåˆ›æ–°ç‚¹ã€‚
    3. è¯­æ°”ä¸“ä¸šä¸”ç²¾ç‚¼ã€‚
    
    è®ºæ–‡æ ‡é¢˜ï¼š{paper['title']}
    è®ºæ–‡æ‘˜è¦ï¼š{paper['summary']}
    """
    try:
        response = client.chat.completions.create(
            model="glm-4-flash",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„å­¦æœ¯åŠ©æ‰‹ã€‚"},
                {"role": "user", "content": prompt}
            ],
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"AIæ€»ç»“å¤±è´¥: {e}"

def push_to_feishu(paper_title, ai_summary, paper_link):
    print("æ­£åœ¨æ¨é€ç¡¬æ ¸æƒ…æŠ¥åˆ°é£ä¹¦...")
    payload = {
        "msg_type": "interactive",
        "card": {
            "config": {"wide_screen_mode": True},
            "header": {
                "title": {"tag": "plain_text", "content": "ğŸ‘‘ é¡¶ä¼šæƒ…æŠ¥é€Ÿé€’ (ç®¡å®¶ç‰¹ä¾›)"},
                "template": "red" 
            },
            "elements": [
                {
                    "tag": "markdown",
                    "content": f"**ğŸ“„ è®ºæ–‡æ ‡é¢˜ï¼š**\n{paper_title}\n\n**ğŸ’¡ æ ¸å¿ƒæç‚¼ï¼š**\n{ai_summary}"
                },
                {"tag": "hr"},
                {
                    "tag": "action",
                    "actions": [
                        {
                            "tag": "button",
                            "text": {"tag": "plain_text", "content": "ğŸ”— ç‚¹å‡»é˜…è¯»åŸæ–‡"},
                            "type": "primary",
                            "url": paper_link
                        }
                    ]
                }
            ]
        }
    }
    response = requests.post(FEISHU_WEBHOOK_URL, json=payload)
    if response.json().get("code") == 0:
        print("âœ… é£ä¹¦æƒ…æŠ¥æ¨é€æˆåŠŸï¼")
    else:
        print(f"âŒ é£ä¹¦æ¨é€å¤±è´¥è¢«æ‹¦æˆªï¼æŠ¥é”™ä¿¡æ¯: {response.json()}")

def push_empty_notice_to_feishu():
    print("æ²¡æœ‰å‘ç°æ–°è®ºæ–‡ï¼Œæ­£åœ¨å‘é£ä¹¦æ±‡æŠ¥å¹³å®‰...")
    payload = {
        "msg_type": "interactive",
        "card": {
            "config": {"wide_screen_mode": True},
            "header": {
                "title": {"tag": "plain_text", "content": "â˜• é¡¶ä¼šé›·è¾¾æ‰«æå®Œæ¯• (ç®¡å®¶æŠ¥å¤‡)"},
                "template": "grey"
            },
            "elements": [
                {
                    "tag": "markdown",
                    "content": "**æŠ¥å‘Šè€æ¿ï¼š**\n\nåˆšåˆšå®Œæˆäº†ä¸€æ¬¡å…¨çƒæœºå™¨äººé¡¶ä¼š/é¡¶åˆŠçš„æ·±åº¦æ‰«æã€‚\n\n**ğŸ” ç»“æœï¼š** åœ¨æ‚¨è®¾å®šçš„æ ¸å¿ƒå…³é”®è¯é¢†åŸŸå†…ï¼Œè¿‡å»å‡ ä¸ªå°æ—¶å†…**æ²¡æœ‰**æ¢æµ‹åˆ°é«˜ä»·å€¼çš„æ–°è®ºæ–‡å‘å¸ƒã€‚\n\næ‚¨å¯ä»¥å®‰å¿ƒå–æ¯å’–å•¡ï¼Œç®¡å®¶ä¼šç»§ç»­åœ¨åå°ä¸ºæ‚¨ç›¯ç›˜ï¼â˜•ï¸"
                }
            ]
        }
    }
    requests.post(FEISHU_WEBHOOK_URL, json=payload)
    print("âœ… æ— æ›´æ–°å¹³å®‰æŠ¥å¤‡æ¨é€æˆåŠŸï¼")

def job():
    papers = fetch_top_tier_papers()
    if not papers:
        push_empty_notice_to_feishu()
        return
    for paper in papers:
        summary = ai_summarize(paper)
        push_to_feishu(paper["title"], summary, paper["link"])
        time.sleep(2)
    print("é¡¶ä¼šæƒ…æŠ¥æ±‡æŠ¥å®Œæ¯•ï¼")

# ================= 4. ä¸»ç¨‹åºå…¥å£ =================
if __name__ == "__main__":
    print("å¯åŠ¨æˆåŠŸï¼å·¥ç¨‹åŒ– AIç®¡å®¶å·²åœ¨åå°å¾…å‘½...")
    schedule.every().day.at("08:30").do(job)
    schedule.every().day.at("18:30").do(job)

    print("æ­£åœ¨è¿›è¡Œé¦–æ¬¡é¡¶ä¼šæ‰«æï¼Œè¯·ç¨å€™...")
    job() 

    while True:
        schedule.run_pending()
        time.sleep(60)